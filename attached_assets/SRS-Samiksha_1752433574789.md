# **Software Requirements Specification (SRS) for Samiksha: A Trend Analysis Tool**

## **1\. Introduction**

### **1.1. Purpose**

The purpose of this document is to define the requirements for a new web application, **Samiksha: A Trend Analysis Tool**, designed to track project trend analysis, identify risks, and highlight achievements based on data provided by project managers. This application will serve as a digital dashboard to provide delivery managers and other stakeholders with a high-level, weekly overview of overall project statuses.

### **1.2. Scope**

The scope of this project includes the design, development, and deployment of a user-friendly digital dashboard for **Samiksha**. It will enable project managers to submit standardized weekly project status updates and allow delivery managers and higher-level stakeholders to view aggregated project health (RAG status), identify trends, and assess potential risks. The application will also facilitate the digitization of technical review reports.

The initial phase will focus on:

* Standardized input for weekly project status.  
* Display of project RAG status and key updates.  
* Basic trend analysis for risk identification.  
* Integration or facilitation of digitized technical review reports.  
* Deployment on a free cloud service within a five-day timeline.

### **1.3. Definitions, Acronyms, and Abbreviations**

* **SRS**: Software Requirements Specification  
* **RAG**: Red, Amber, Green (status indicators for project health)  
* **AI**: Artificial Intelligence  
* **PM**: Project Manager  
* **DM**: Delivery Manager  
* **UI**: User Interface  
* **UX**: User Experience  
* **CSV**: Comma Separated Values  
* **DocX**: Microsoft Word Document  
* **SSO**: Single Sign-On  
* **LLM**: Large Language Model

### **1.4. References**

* Meeting Summary provided by read.ai (July 11, 2025\)  
* Technical\_Review\_Checklist.xlsx \- Sheet1.csv  
* Technical\_Review\_Report\_Template.docx  
* Weekly Status Report.xlsx \- WSR Week 28.csv

## **2\. Overall Description**

### **2.1. Product Perspective**

**Samiksha: A Trend Analysis Tool** will be a standalone digital dashboard, accessible via a web browser. It will replace or augment the current manual/spreadsheet-based project tracking methods, providing a centralized and standardized platform for project status reporting and analysis.

### **2.2. Product Functions**

The primary functions of **Samiksha** include:

* **Project Status Reporting**: Allow project managers to submit weekly project status updates with standardized criteria.  
* **Automated Project Status Analysis via LLM**: Process submitted project status data through a configured Large Language Model to generate AI-driven RAG status assessments and detailed analysis.  
* **RAG Status Visualization**: Display project health using Red, Amber, Green indicators based on defined parameters, including LLM-generated insights.  
* **Trend Analysis**: Enable the identification of project trends over time to predict potential risks and highlight achievements, augmented by LLM analysis.  
* **Key Updates Display**: Provide a section for project managers to add brief weekly updates.  
* **Technical Review Report Management**: Facilitate the digitization and access of technical review reports.  
* **User Management**: Manage user roles and access permissions (e.g., Project Manager, Delivery Manager, Administrator).

### **2.3. User Characteristics**

* **Project Managers (PMs)**:  
  * **Role**: Primary data providers.  
  * **Needs**: Easy-to-use interface for submitting weekly project status, including RAG status, key updates, project importance, and client escalations.  
  * **Skills**: Familiar with project management concepts, basic web application usage.  
* **Delivery Managers (DMs) and Above**:  
  * **Role**: Primary data consumers and LLM configuration managers.  
  * **Needs**: High-level overview of all projects, ability to quickly identify at-risk projects, view trends, and access key updates. Ability to configure LLM settings and review LLM-generated insights.  
  * **Skills**: Familiar with project management and reporting, basic web application usage.  
* **Administrators**:  
  * **Role**: System configuration and user management, including primary responsibility for LLM provider and model configuration.  
  * **Needs**: Manage user accounts, define project parameters, potentially configure reporting fields, configure and manage LLM settings.  
  * **Skills**: Technical understanding of web applications.

### **2.4. General Constraints**

* **Timeline**: Initial version to be completed within five (5) days.  
* **Deployment Environment**: Must be deployed on a free cloud service.  
* **Technology Stack**: Web-based application (HTML, CSS, JavaScript, potentially a light framework if needed for speed of development).  
* **Data Source**: Initial data input will be manual via the web application. Future integration with existing Weekly Status Report.xlsx might be considered but is out of scope for the initial 5-day delivery.  
* **Security**: Basic authentication and authorization (e.g., user login, role-based access).

### **2.5. Assumptions and Dependencies**

* **Assumptions**:  
  * Project managers will consistently provide weekly updates.  
  * Standardized criteria for RAG status can be quickly defined and implemented.  
  * A free cloud service with sufficient capabilities for the initial deployment is available.  
  * Team collaboration and daily meetings will ensure clarity and progress.  
  * The chosen LLM provider offers an API for programmatic access and can adhere to the specified JSON schema for responses.  
* **Dependencies**:  
  * Availability of project managers and delivery managers for feedback and testing.  
  * Clear definition of standardized RAG criteria and data points for reporting.  
  * Access to and configuration details for the selected LLM provider and model.

## **3\. Specific Requirements**

### **3.1. Functional Requirements**

#### **3.1.1. User Authentication and Authorization**

* **FR1.1**: The system shall support user authentication via Single Sign-On (SSO), including Google SSO, and other standard identity providers, eliminating the need for the application to maintain user passwords.  
* **FR1.2**: The system shall differentiate between user roles (e.g., Project Manager, Delivery Manager, Administrator).  
* **FR1.3**: Project Managers shall only be able to submit/edit their assigned project statuses.  
* **FR1.4**: Delivery Managers and above shall have the ability to view and edit all project statuses and reports.  
* **FR1.5**: Administrators and Delivery Managers shall be able to configure LLM provider and model settings.

#### **3.1.2. Project Status Reporting (For Project Managers)**

* **FR2.1**: The system shall provide a form for project managers to submit weekly project status updates.  
* **FR2.2**: The form shall include fields for:  
  * Project Name (pre-populated or selectable)  
  * Reporting Week/Date  
  * Project Importance (e.g., High, Medium, Low)  
  * Delivery Model  
  * Client Escalations (Yes/No, with a text field for details if Yes)  
  * Project Health RAG Status (Red, Amber, Green)  
  * Key Weekly Updates (text area for brief summary)  
  * A column for weekly updates to enhance data accuracy (as suggested by Ani Sundaresan Menon).  
* **FR2.3**: The system shall enforce standardized criteria for RAG status marking (e.g., based on predefined rules or a simple dropdown selection with guidance). *Initial implementation may be a simple dropdown, with future enhancements for rule-based automation.*  
* **FR2.4**: The system shall allow project managers to view and edit their previously submitted weekly reports.  
* **FR2.5**: Upon submission of a weekly project status report, **Samiksha** shall automatically process the relevant project status data through the configured LLM to generate an AI-driven RAG status and assessment.

#### **3.1.3. Project Dashboard (For Delivery Managers and Above)**

* **FR3.1**: The system shall display a dashboard providing a high-level overview of all projects.  
* **FR3.2**: The dashboard shall clearly show the current RAG status for each project.  
* **FR3.3**: The dashboard shall allow filtering and sorting of projects (e.g., by RAG status, project importance).  
* **FR3.4**: The dashboard shall display key weekly updates for each project.  
* **FR3.5**: The system shall provide a historical view of project RAG statuses to identify trends.  
* **FR3.6**: The system shall allow drilling down into individual project details to view historical data and full weekly updates.  
* **FR3.7**: The dashboard shall display the LLM's ai\_status and ai\_assessment\_description for each project, as well as the overall\_portfolio\_rag\_status and its reason from the LLM's response.

#### **3.1.4. Technical Review Report Management**

* **FR4.1**: The system shall provide a section to view digitized technical review reports, based on the Technical\_Review\_Report\_Template.docx.  
* **FR4.2**: The system shall allow for data entry corresponding to the sections in the Technical\_Review\_Report\_Template.docx (e.g., Project Details, Architecture & Design Review, Code Quality, etc.). *Initial implementation might be a simple form for manual entry, with future consideration for automated parsing.*  
* **FR4.3**: The system shall allow users with appropriate permissions (e.g., Project Managers, Administrators) to input and update technical review report data.

#### **3.1.5. Data Analysis and Risk Identification**

* **FR5.1**: The system shall enable basic data analysis to identify potential risks based on trends in RAG status and client escalations.  
* **FR5.2**: The system shall highlight projects that have consistently been in 'Amber' or 'Red' status for a configurable number of weeks.  
* **FR5.3**: The system shall display a summary of projects with active client escalations.

#### **3.1.6. LLM Integration and Configuration**

* **FR6.1**: **Samiksha** shall integrate with a Large Language Model (LLM) API as a **core component** to perform automated, intelligent analysis of submitted project status data.  
* **FR6.2**: The system shall allow Administrators and Delivery Managers to configure the LLM provider (e.g., Google, OpenAI) and the specific model (e.g., gemini-2.0-flash) to be used for analysis via an administrative screen. These configurations shall be stored persistently in the database.  
* **FR6.3**: When submitting project status data to the LLM, the system shall use the following JSON schema to structure the expected response:  
  {  
    "$schema": "http://json-schema.org/draft-07/schema\#",  
    "type": "object",  
    "properties": {  
      "analysis\_summary": {  
        "type": "object",  
        "properties": {  
          "overall\_portfolio\_rag\_status": {  
            "type": "string",  
            "enum": \["Green", "Amber", "Red"\]  
          },  
          "reason": {  
            "type": "string"  
          }  
        },  
        "required": \["overall\_portfolio\_rag\_status", "reason"\]  
      },  
      "projects": {  
        "type": "array",  
        "items": {  
          "type": "object",  
          "properties": {  
            "project\_name": {  
              "type": "string"  
            },  
            "ai\_status": {  
              "type": "string",  
              "enum": \["Green", "Amber", "Red"\]  
            },  
            "ai\_assessment\_description": {  
              "type": "string"  
            },  
            "key\_columns\_used": {  
              "type": "object",  
              "properties": {  
                "Health (Week 28)": {  
                  "type": "string"  
                },  
                "Update for the Current Week": {  
                  "type": "string"  
                },  
                "Issues/Challenges": {  
                  "type": "string"  
                },  
                "Path to Green": {  
                  "type": "string"  
                },  
                "SQA Remarks": {  
                  "type": "string"  
                }  
              },  
              "required": \[  
                "Health (Week 28)",  
                "Update for the Current Week"  
              \]  
            }  
          },  
          "required": \[  
            "project\_name",  
            "ai\_status",  
            "ai\_assessment\_description",  
            "key\_columns\_used"  
          \]  
        }  
      },  
      "metadata": {  
        "type": "object",  
        "properties": {  
          "columns\_used\_for\_analysis": {  
            "type": "array",  
            "items": {  
              "type": "string"  
            }  
          },  
          "note": {  
            "type": "string"  
          }  
        },  
        "required": \["columns\_used\_for\_analysis"\]  
      }  
    },  
    "required": \["analysis\_summary", "projects", "metadata"\]  
  }

* **FR6.4**: The prompt sent to the LLM for analysis shall be structured to include the project status data and the above JSON schema. The prompt will be:  
  Analyze the Input Data given in json format and return the RAG status assessment for all projects. Use the following JSON schema for the response:

  \<PASTE YOUR SCHEMA HERE\>

  Input Data:  
  \<PASTE YOUR INPUT DATA HERE\>

* **FR6.5**: The LLM's analysis (ai\_status, ai\_assessment\_description, overall\_portfolio\_rag\_status, reason) shall be stored alongside the project status data in the Weekly\_Status\_Report table and displayed in the Delivery Manager Dashboard.  
* **FR6.6**: The LLM shall consistently use the logic defined by the columns\_used\_for\_analysis in the provided schema for its analysis. Specifically:  
  * AI\_STATUS will default to the value in "Health (Week 28)" unless contradictions are found in other columns (e.g., unresolved blockers in "Issues/Challenges").  
  * AI\_ASSESSMENT will synthesize data *only* from the schema’s defined columns: "Health (Week 28)", "Update for the Current Week", "Issues/Challenges", "Path to Green", and "SQA Remarks". Even if the new dataset has extra columns (e.g., "Budget" or "Risk Score"), the LLM will ignore them unless they are explicitly added to the schema's columns\_used\_for\_analysis.

## **3.2. Non-Functional Requirements**

#### **3.2.1. Performance**

* **NFR1.1**: The dashboard should load within 3-5 seconds for up to 50 concurrent users.  
* **NFR1.2**: Project status submission (including LLM analysis) should be processed within 5 seconds.

#### **3.2.2. Security**

* **NFR2.1**: User authentication shall be secure (e.g., hashed passwords).  
* **NFR2.2**: Role-based access control shall be strictly enforced.  
* **NFR2.3**: All data transmission between the client and server shall be encrypted (HTTPS).  
* **NFR2.4**: API keys or credentials for LLM providers shall be securely stored and managed (e.g., using secret management services).

#### **3.2.3. Usability**

* **NFR3.1**: The user interface shall be intuitive and easy to navigate for all user roles.  
* **NFR3.2**: The application shall be responsive and accessible on various devices (desktop, tablet, mobile).  
* **NFR3.3**: Error messages shall be clear and actionable.

#### **3.2.4. Reliability**

* **NFR4.1**: The system shall have an uptime of at least 99%.  
* **NFR4.2**: Data integrity shall be maintained, ensuring no data loss during submission or retrieval.  
* **NFR4.3**: The system shall handle potential LLM API failures gracefully (e.g., retries, fallback mechanisms, error messages).

#### **3.2.5. Maintainability**

* **NFR5.1**: The code shall be well-documented and follow established coding standards.  
* **NFR5.2**: The architecture shall allow for future enhancements and module additions (e.g., AI integration).

#### **3.2.6. Scalability**

* **NFR6.1**: The chosen free cloud service should support potential growth in the number of projects and users.  
* **NFR6.2**: The LLM integration should be scalable to handle the expected volume of analysis requests.

## **4\. Data Model (Conceptual)**

The following ER Diagram illustrates the relationships between the core entities within the application's database.

erDiagram  
USER {  
string User\_ID PK  
string Username  
string Password  
string Role  
}  
PROJECT {  
string Project\_ID PK  
string Project\_Name  
string Project\_Code\_ID  
string Customer\_Name  
string Engagement\_Type  
string Project\_Manager\_ID FK  
boolean Is\_Active  
}  
PROJECT\_STATUS {  
string Status\_ID PK  
string Project\_ID FK  
date Reporting\_Date  
string Project\_Importance  
string Delivery\_Model  
boolean Client\_Escalation  
string Client\_Escalation\_Details  
string RAG\_Status  
string Key\_Weekly\_Updates  
string Weekly\_Update\_Column  
}  
PROJECT\_REVIEW {  
string Review\_ID PK  
string Project\_ID FK  
date Review\_Date  
string Review\_Type  
int Review\_Cycle\_Number  
string Executive\_Summary  
string Architecture\_Design\_Review  
string Code\_Quality\_Standards  
string DevOps\_Deployment\_Readiness  
string Testing\_QA  
string Risk\_Identification  
string Compliance\_Standards  
string Action\_Items\_Recommendations  
string Reviewer\_Sign\_off  
string SQA\_Validation  
}  
PROJECT\_REVIEW\_PARTICIPANT {  
string Review\_ID FK  
string Participant\_Name  
}  
PROJECT\_REVIEW\_CONDUCTOR {  
string Review\_ID FK  
string User\_ID FK  
}  
USER ||--o{ PROJECT : manages    
PROJECT ||--o{ PROJECT\_STATUS : has    
PROJECT ||--o{ PROJECT\_REVIEW : has    
PROJECT\_REVIEW ||--o{ PROJECT\_REVIEW\_PARTICIPANT : includes    
PROJECT\_REVIEW ||--o{ PROJECT\_REVIEW\_CONDUCTOR : conducted\_by    
USER ||--o{ PROJECT\_REVIEW\_CONDUCTOR : is\_conductor

**Explanation of ER Diagram and Entities:**

* **USER:** Represents individual users of the application.  
  * User\_ID (Primary Key): Unique identifier for each user.  
  * Username: User's login name.  
  * Password: (Though SSO is used, this field might exist for internal system accounts or be deprecated).  
  * Role: Defines the user's access level (e.g., Project Manager, Delivery Manager).  
* **PROJECT:** Represents individual projects being tracked.  
  * Project\_ID (Primary Key): Unique identifier for each project.  
  * Project\_Name, Project\_Code\_ID, Customer\_Name, Engagement\_Type, Is\_Active: Core project details.  
  * Project\_Manager\_ID (Foreign Key): Links to the USER table, indicating which user manages the project.  
* **PROJECT\_STATUS:** Stores weekly status updates for projects.  
  * Status\_ID (Primary Key): Unique identifier for each status report.  
  * Project\_ID (Foreign Key): Links to the PROJECT table.  
  * Reporting\_Date, Project\_Importance, Delivery\_Model, Client\_Escalation, Client\_Escalation\_Details, RAG\_Status, Key\_Weekly\_Updates, Weekly\_Update\_Column: Details of the weekly status.  
* **PROJECT\_REVIEW:** Stores data related to technical review reports.  
  * Review\_ID (Primary Key): Unique identifier for each review report.  
  * Project\_ID (Foreign Key): Links to the PROJECT table.  
  * Review\_Date, Review\_Type, Review\_Cycle\_Number, Executive\_Summary, Architecture\_Design\_Review, Code\_Quality\_Standards, DevOps\_Deployment\_Readiness, Testing\_QA, Risk\_Identification, Compliance\_Standards, Action\_Items\_Recommendations, Reviewer\_Sign\_off, SQA\_Validation: Various details from the technical review template.  
* **PROJECT\_REVIEW\_PARTICIPANT:** A junction entity to list participants in a technical review.  
  * Review\_ID (Foreign Key): Links to the PROJECT\_REVIEW table.  
  * Participant\_Name: Name of a participant in the review.  
* **PROJECT\_REVIEW\_CONDUCTOR:** A junction entity to link users who conducted a review.  
  * Review\_ID (Foreign Key): Links to the PROJECT\_REVIEW table.  
  * User\_ID (Foreign Key): Links to the USER table.  
    Relationships:  
* USER ||--o{ PROJECT: A User manages zero or many Projects.  
* PROJECT ||--o{ PROJECT\_STATUS: A Project has zero or many Project Status reports.  
* PROJECT ||--o{ PROJECT\_REVIEW: A Project has zero or many Project Reviews.  
* PROJECT\_REVIEW ||--o{ PROJECT\_REVIEW\_PARTICIPANT: A Project Review includes zero or many Participants.  
* PROJECT\_REVIEW ||--o{ PROJECT\_REVIEW\_CONDUCTOR: A Project Review is conducted by zero or many Conductors.  
* USER ||--o{ PROJECT\_REVIEW\_CONDUCTOR: A User can be a conductor for zero or many Project Reviews.  
* **LLM\_Configuration:**  
  * Config\_ID (Primary Key): Unique identifier for the configuration.  
  * Provider\_Name: String (e.g., "Google", "OpenAI", “DeepSeek”).  
  * Model\_Name: String (e.g., "gemini-2.0-flash", "gpt-4o").  
  * API\_Key: String (securely stored/encrypted).  
  * Last\_Updated\_By: String (User\_ID of the last modifier).  
  * Last\_Updated\_Date: Date/Timestamp.  
  * Is\_Active: Boolean (to enable/disable configurations).

## **5\. User Interface Requirements (High-Level)**

* **Login Page**: Simple and secure login form.  
* **Project Manager Dashboard/Form**:  
  * Clear form fields for weekly updates.  
  * Dropdowns for standardized selections (RAG, Importance).  
  * Text areas for detailed comments.  
  * "Save" and "Submit" buttons.  
  * History view of their own submissions.  
* **Delivery Manager Dashboard**:  
  * Table or card view of all projects.  
  * Color-coded RAG status indicators.  
  * Filtering and sorting options.  
  * Clickable project names to view details.  
  * Trend graphs/charts (basic line charts for RAG history).  
  * **Display of LLM Analysis:** Show AI Status, AI Assessment Description, Overall Portfolio RAG Status, and Overall Reason from LLM.  
* **Technical Review Report View/Edit**:  
  * Form fields mirroring the Technical\_Review\_Report\_Template.docx.  
  * Read-only view for unauthorized users.  
* **Admin/DM LLM Configuration Screen (New):**  
  * A dedicated screen accessible by Administrators and Delivery Managers.  
  * Fields to input LLM Provider Name, Model Name, and API Key.  
  * Buttons to Save, Update, and Test the configuration.  
  * Display of current active LLM configuration.

## **6\. Diagrams**

### **6.1. Context Diagram**

graph TD  
    A\[Project Manager\] \--\>|Submits Weekly Status, Views Own Reports| 
    B(Samiksha: A Trend Analysis Tool)  
    C\[Delivery Manager and Above\] \--\>|Views Dashboard, Edits Reports, Views Audit Log, Configures LLM, Manages Projects| B  
    B \--\>|Displays Dashboard, Provides Reports, LLM Analysis Results| A  
    B \--\>|Displays Dashboard, Provides Reports, Tracks Changes, LLM Analysis Results| C  
    B \-- LLM API Call (Project Status Data, JSON Schema) \--\> D\[LLM Provider\]  
    D \-- LLM Response (AI Status, Assessment, Overall RAG) \--\> B

### **6.2. DFD Level-1: High-Level System Overview**

graph TD  
    subgraph System: Samiksha: A Trend Analysis Tool  
        P1\[Project Status Management\]  
        P2\[Technical Review Management\]  
        P3\[Data Analysis & Reporting\]  
        P4\[LLM Integration & Configuration\]  
        P5\[Project Administration\]  
        D1\[Project Data Store\]  
        D2\[Weekly Status Reports Store\]  
        D3\[Technical Review Reports Store\]  
        D4\[User Data Store\]  
        D5\[LLM Configuration Store\]  
    end

    D4 \--\>|User Roles| P1  
    D4 \--\>|User Roles| P2  
    D4 \--\>|User Roles| P3  
    D4 \--\>|User Roles| P4  
    D4 \--\>|User Roles| P5

    A\[Project Manager\] \--\>|Weekly Status Input| P1  
    P1 \--\>|Store Weekly Status| D2  
    D2 \--\>|Retrieve Weekly Status| P1  
    P1 \--\>|Update Project Info| D1  
    D1 \--\>|Project Info| P1  
    P1 \-- Project Status Data \--\> P4  
    P4 \-- LLM Analysis Results \--\> P1  
    P1 \--\>|Store LLM Analysis Results| D2

    A \--\>|Input Technical Review Data| P2  
    C\[Delivery Manager & Above\] \--\>|View/Edit Technical Review| P2  
    P2 \--\>|Store/Update Technical Review| D3  
    D3 \--\>|Retrieve Technical Review| P2

    A \--\>|View Own Reports Request| P3  
    C \--\>|View Dashboard Request| P3  
    P3 \--\>|Own Project Data| A  
    P3 \--\>|Aggregated Project Data & LLM Analysis| C  
    D1 \--\>|Project Data| P3  
    D2 \--\>|Weekly Status Data & LLM Analysis| P3

    C \--\>|Edit Project Status| P1  
    C \--\>|Configure LLM Settings| P4  
    P4 \--\>|Store LLM Config| D5  
    D5 \--\>|Retrieve LLM Config| P4

    C \--\>|Add/Edit/Delete Project| P5  
    P5 \--\>|Update Project Data| D1  
    D1 \--\>|Project Data| P5

    LLM\[Large Language Model\] \-- LLM API Call (Configured Model, Data, Schema) \--\> P4  
    P4 \-- LLM Response (Structured Analysis) \--\> LLM

Purpose: Illustrates the main functional modules of Samiksha and their interactions with users, LLM, and data stores.  
Main Processes:

* **Project Status Management (P1):** Handles input, update, and retrieval of weekly project status information. Now also responsible for initiating LLM analysis and storing its results.  
* **Technical Review Management (P2):** Manages the creation, update, and retrieval of technical review reports.  
* **Data Analysis & Reporting (P3):** Aggregates project and status data to provide dashboards and reports for users, now including LLM-generated insights.  
* **LLM Integration & Configuration (P4):** Manages the configuration of LLM providers/models and handles the communication with the external LLM service for analysis.  
* Project Administration (P5): Handles the creation, modification, and deletion of project entities.  
  Data Stores:  
* **Project Data Store (D1):** Stores core project information.  
* **Weekly Status Reports Store (D2):** Stores weekly status updates for each project, now including LLM analysis results.  
* **Technical Review Reports Store (D3):** Stores technical review documents and related data.  
* **User Data Store (D4):** Maintains user roles and permissions (for process access control).  
* LLM Configuration Store (D5): Stores the configured LLM provider, model, and API key.  
  External Entities:  
* **Project Manager (A):** Submits and views project status and technical review data.  
* **Delivery Manager & Above (C):** Views dashboards, edits reports, accesses technical reviews, configures LLM settings, and manages projects.  
* Large Language Model (LLM): The external AI service that performs the project status analysis.  
  Key Data Flows:  
* Submission and retrieval of project status and technical review data.  
* Dashboard and report requests from users, now enriched with LLM analysis.  
* Role-based access to processes and LLM configuration.  
* New data flow: Project status data from P1 to P4 for LLM analysis, and LLM analysis results back to P1 for storage.  
* New data flow: Project administration operations from C to P5, and project data updates to D1.

### **6.3. DFD Level-2: Detailed Process Decomposition (Project Status Management Example)**

graph TD  
    subgraph System: Samiksha: A Trend Analysis Tool  
        P1\[Project Status Management\]  
        P2\[Technical Review Management\]  
        P3\[Data Analysis & Reporting\]  
        D1\[Project Data Store\]  
        D2\[Weekly Status Reports Store\]  
        D3\[Technical Review Reports Store\]  
        D4\[User Data Store\]  
    end

    D4 \--\>|User Roles| P1  
    D4 \--\>|User Roles| P2  
    D4 \--\>|User Roles| P3

    A\[Project Manager\] \--\>|Edit Project Status| P1  
    C\[Delivery Manager & Above\] \--\>|Edit Project Status| P1  
    P1 \--\>|Update Project Status| D1  
    P1 \--\>|Update Weekly Status| D2

    A \--\>|View/Edit Technical Review| P2  
    C \--\>|View/Edit Technical Review| P2  
    P2 \--\>|Update Technical Review| D3

    C \--\>|View Dashboard Request| P3  
    P3 \--\>|Aggregated Project Data| C  
    D1 \--\>|Project Data| P3  
    D2 \--\>|Weekly Status Data| P3

Purpose: Provides a detailed breakdown of the "Project Status Management" process from Level-1, showing internal sub-processes and data flows.  
Detailed Processes:

* **Edit Project Status:** Allows Project Managers and Delivery Managers to update project status information.  
* **Update Project Status:** Saves updated project information to the Project Data Store.  
* **Update Weekly Status:** Saves weekly status updates to the Weekly Status Reports Store.  
* **Technical Review Management:**  
  * **View/Edit Technical Review:** Both Project Managers and Delivery Managers can view or edit technical review reports.  
  * **Update Technical Review:** Saves changes to the Technical Review Reports Store.  
* **Data Analysis & Reporting:**  
  * **View Dashboard Request:** Delivery Managers request aggregated project data for dashboard visualization.  
  * Aggregated Project Data: System provides processed and summarized project data for management review.  
    Data Stores:  
* **Project Data Store:** Receives and provides project information.  
* **Weekly Status Reports Store:** Receives and provides weekly status data.  
* **Technical Review Reports Store:** Receives and provides technical review data.  
* User Data Store: Used for role validation in process access.  
  Key Data Flows:  
* Role-based access to editing and viewing functions.  
* Updates to project and status data stores.  
* Retrieval of data for dashboards and reports.

## **7\. High-Level Backend APIs**

This section outlines the high-level Application Programming Interfaces (APIs) that will expose the application's functionality to the frontend and potentially to future external integrations. These APIs will serve as the communication layer between the user interface and the backend data and logic.

### **7.1. Purpose of APIs**

The APIs are essential for:

* Enabling the web application's frontend to interact with the backend data stores (e.g., submitting new project statuses, fetching dashboard data).  
* Facilitating future integration with external project management tools (e.g., JIRA, ServiceNow) to automate data ingestion or synchronization.  
* Ensuring standardized and secure access to application data and business logic.

### **7.2. API Categories**

The APIs can be broadly categorized based on the functional areas of the application:

* **Project Status APIs:** For managing weekly project status updates.  
* **Project Data APIs:** For managing core project information.  
* **Technical Review APIs:** For managing technical review reports.  
* **User Management APIs:** For user-related operations (authentication, role retrieval).  
* **Reporting & Analytics APIs:** For fetching aggregated data and trends for dashboards.  
* **LLM Integration APIs:** For managing LLM configurations and invoking LLM analysis.

### **7.3. Key Endpoints (High-Level Examples)**

The following are high-level examples of API endpoints, primarily following RESTful principles, and using JSON for data exchange.

#### **7.3.1. Project Status APIs**

* POST /api/projects/{projectId}/trend: Submit a new weekly status report for a specific project. This endpoint will also trigger the LLM analysis.  
* GET /api/projects/{projectId}/trend/{reportId}: Retrieve a specific weekly status report, including its LLM analysis results.  
* PUT /api/projects/{projectId}/trend/{reportId}: Update an existing weekly status report. This may also trigger re-analysis by the LLM.  
* GET /api/projects/{projectId}/trend: Retrieve all weekly status reports for a project (e.g., for historical view), including LLM analysis results.

#### **7.3.2. Project Data APIs**

* GET /api/projects: Retrieve a list of all projects (filtered by user role/permissions).  
* GET /api/projects/{projectId}: Retrieve details of a specific project.  
* POST /api/projects: Create a new project.  
* PUT /api/projects/{projectId}: Update core project information (e.g., Project Importance, Delivery Model).  
* DELETE /api/projects/{projectId}: Delete a project and its associated data.

#### **7.3.3. Technical Review APIs**

* POST /api/projects/{projectId}/reviews: Submit a new technical review report.  
* GET /api/projects/{projectId}/reviews/{reviewId}: Retrieve a specific technical review report.  
* PUT /api/projects/{projectId}/reviews/{reviewId}: Update an existing technical review report.  
* DELETE /api/projects/{projectId}/reviews/{reviewId}: Delete a technical review report.  
* GET /api/projects/{projectId}/reviews: Retrieve all technical review reports for a project.

#### **7.3.4. User Management APIs**

* GET /api/users/me: Retrieve current authenticated user's profile and roles.  
* *(Note: User login/SSO is handled externally by the SSO provider, not directly via a custom API endpoint for password-based login.)*

#### **7.3.5. Reporting & Analytics APIs**

* GET /api/dashboard/summary: Retrieve aggregated data for the main dashboard view (e.g., RAG counts, projects with escalations), including LLM-derived overall portfolio status.  
* GET /api/dashboard/trends/{projectId}: Retrieve historical RAG status data for trend analysis of a specific project, including LLM-derived AI statuses.

#### **7.3.6. LLM Integration APIs (New)**

* POST /api/llm/analyze-status: Internal API endpoint to send project status data to the configured LLM and receive its analysis. This will be called by the Project Status APIs.  
* GET /api/llm/configuration: Retrieve the current LLM provider and model configuration.  
* PUT /api/llm/configuration: Update the LLM provider and model configuration. (Admin/DM only)  
* POST /api/llm/configuration/test: Test the configured LLM connection and model. (Admin/DM only)

### **7.4. Authentication and Authorization**

All API endpoints will be secured.

* **Authentication:** Achieved through the Single Sign-On (SSO) mechanism (e.g., Google SSO). The backend APIs will validate the authenticity of the user's session/token provided by the SSO provider.  
* **Authorization:** Role-Based Access Control (RBAC) will be enforced at the API level. API calls will check the user's role (Project Manager, Delivery Manager, Administrator) to determine if they have the necessary permissions to perform the requested operation (e.g., Project Managers can only update their assigned projects; Delivery Managers can update all projects and view audit logs; Admins/DMs can configure LLM settings).

### **7.5. Data Formats**

* All API requests and responses will primarily use **JSON (JavaScript Object Notation)** for data serialization and deserialization due to its lightweight nature and widespread compatibility with web applications.

## **8\. Infrastructure Considerations**

For an internal web application with a very small number of users, focusing on cost-effectiveness and ease of management, the following infrastructure is suggested, primarily leveraging free or low-cost cloud resources.

### **8.1. Cloud Platform**

The application will primarily leverage major cloud providers like **Google Cloud Platform (GCP)** or **Amazon Web Services (AWS)**. Both offer robust services and free tiers that can be utilized for initial development and low-usage scenarios.

### **8.2. Compute (Web Application Hosting)**

Given that Cloud Functions are explicitly excluded, the compute strategy will focus on virtual machines or container services that allow for more direct control over the application environment.

* **Option A: Small Virtual Machine (VM) \- Recommended for Free Tier Eligibility**  
  * **Service:** Google Compute Engine (GCP) or AWS EC2.  
  * **Configuration (Example for GCP):** e2-micro instance (eligible for GCP's Always Free tier for up to 750 hours/month).  
  * **Configuration (Example for AWS):** t2.micro or t3.micro instance (eligible for AWS Free Tier for up to 750 hours/month).  
  * **CPU/RAM:** Typically 1 vCPU and 1 GB RAM.  
  * **Operating System:** A lightweight Linux distribution (e.g., Ubuntu Server, Debian, Amazon Linux).  
  * **Storage:** 10-30 GB Standard Persistent Disk (GCP) or General Purpose SSD (gp2/gp3 on AWS). Free tiers often include a certain amount of disk space.  
  * **Benefits:** Cost-effective for low usage, provides full control over the environment for Spring Boot and Docker.  
  * **Considerations:** Requires manual server management (OS updates, security patches, application deployment, Docker management).  
* **Option B: Container Service (if budget allows beyond free tier)**  
  * **Service:** Google Cloud Run (for stateless services) or AWS Elastic Container Service (ECS) with Fargate launch type.  
  * **Benefits:** Managed container orchestration, scales automatically, less server management than raw VMs.  
  * **Considerations:** While offering free tiers for requests/compute time, persistent services might incur costs sooner than a free-tier VM. More complex to set up initially than a single VM.

Recommendation for Free Web Hosting for the Entire Application (Frontend \+ Backend):  
For a truly "free" experience that encompasses both frontend and a Spring Boot backend, the most viable option within the free tiers of major cloud providers would be to deploy the Spring Boot application on a small Virtual Machine (VM) like GCP's e2-micro or AWS's t2.micro/t3.micro. These instances typically offer enough free hours per month to run a small, internal application continuously. The frontend (ReactJS) would then be served directly by the Spring Boot application or deployed as static files on a service like Firebase Hosting (which has a very generous free tier for static content) with the React app making API calls to the Spring Boot backend on the VM.

### **8.3. Database**

For database persistence, aligning with "free db" and managed services:

* **Option A: Firestore (Recommended \- NoSQL Document Database)**  
  * **Service:** Cloud Firestore (Firebase/GCP)  
  * **Type:** NoSQL, document-oriented database.  
  * **Benefits:**  
    * **Generous Free Tier:** Includes 1GB storage, 50,000 reads, 20,000 writes, 20,000 deletes per day. This is usually more than enough for a small internal app.  
    * **Managed Service:** No database server to manage, scale, or patch.  
    * **Real-time Capabilities:** Easy to build real-time dashboards.  
    * **Integration:** Seamlessly integrates with Firebase Authentication (for SSO) and other GCP services.  
    * **No Password Management:** As a managed service, you don't directly manage database user passwords; access is controlled via Firebase security rules and authenticated users.  
  * **Data Model Fit:** Well-suited for storing project documents, weekly reports, and audit logs as collections of documents.  
* **Option B: PostgreSQL (Relational Database)**  
  * **Service:** Cloud SQL for PostgreSQL (GCP), AWS RDS for PostgreSQL.  
  * **Type:** Relational database.  
  * **Configuration:** Smallest available instance types (e.g., db-f1-micro on Cloud SQL, or db.t3.micro on AWS RDS).  
  * **Storage:** 10-20 GB SSD.  
  * **Considerations:**  
    * **Cost:** While small instances exist, they generally have less generous free tiers or start incurring costs sooner than Firestore.  
    * **Management:** Still a managed service, but requires more configuration for backups, scaling, and connection management compared to Firestore's simpler API.  
    * **Password Management:** You would need to manage database user passwords within the cloud provider's console.

### **8.4. Networking & Security**

* **DNS:** Standard DNS service (e.g., Google Cloud DNS, AWS Route 53\) to map a custom domain (e.g., projects.your-org.com) to your application. Free if using Firebase Hosting's provided URL for the frontend.  
* **SSL/TLS:** Essential for secure communication (HTTPS). Most cloud hosting services (like Firebase Hosting, or load balancers in front of VMs) provide free SSL certificates.  
* **Firewall Rules:** If using a VM, configure basic firewall rules to only allow necessary incoming traffic (e.g., HTTP/S on ports 80/443, SSH from specific IPs).  
* **Authentication:** Leverage **Google SSO** as the primary authentication mechanism. The system should also be designed to integrate with **other standard identity providers** (e.g., OAuth2, OpenID Connect compatible services) to allow flexibility in the future. The backend will validate tokens from these providers.

### **8.5. Summary Infrastructure Recommendation**

For an internal app with very few users, a focus on "no passwords," and leveraging "free cloud service" options, the most streamlined and cost-effective infrastructure would be:

* **Frontend Hosting:** **Firebase Hosting** (for static ReactJS build).  
* **Backend Hosting:** A **small Virtual Machine** (e.g., GCP e2-micro or AWS t2.micro/t3.micro) running Docker with the Spring Boot application.  
* **Database:** **Cloud Firestore** (for its generous free tier and managed nature).  
* **Authentication:** **Firebase Authentication** integrated with **Google SSO** and extensible to other identity providers.

This combination offers a robust free tier, minimal operational overhead for the database and frontend, and aligns well with the Spring Boot/Docker backend choice.

## **9\. Development Environment**

This section outlines the key technologies and tools that will be used in the development environment for both frontend and backend components.

### **9.1. Frontend Development Environment**

* **Framework/Library:** ReactJS  
* **Markup:** HTML  
* **Styling:** CSS (potentially with a framework like Tailwind CSS for utility-first approach)  
* **Build Tool:** npm or Yarn  
* **Chart Library:** Recharts or Chart.js (for interactive and visually appealing charts)  
* **Version Control:** Git

### **9.2. Backend Development Environment**

* **Language:** Java 17 or above  
* **Framework:** Spring Boot 3  
* **Build Tool:** Maven (multi module)  
* **Containerization:** Docker (for consistent development and deployment environments)  
* **Database (Development):** PostgreSQL (for local development and testing, can be run in a Docker container)  
* **IDE:** IntelliJ IDEA, Eclipse, or VS Code with Java extensions or Cursor or Windsurf  
* **Version Control:** Git

## **10\. Future Enhancements (Out of Scope for Initial 5-Day Delivery)**

* **Audit Logging**: Implement comprehensive tracking of all modifications made to project statuses and reports, including old/new values, user, and timestamp.  
* **Advanced AI Integration (beyond initial LLM analysis)**:  
  * AI-driven predictions for project risk assessment based on historical data and sentiment analysis of text updates.  
  * Automated summarization of requirements and project updates using AI tools.  
* **Integration with External Systems**:  
  * API integration with existing project management tools (e.g., JIRA, ServiceNow, Azure DevOps, Asana, Trello) or data sources (e.g., direct import from Weekly Status Report.xlsx files).  
* **Customizable Dashboards**: Allow users to customize their dashboard views.  
* **Notifications**: Email or in-app notifications for critical project status changes or upcoming deadlines.  
* **Reporting**: Generation of printable reports.